{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d241fe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from pyexplain.benchmark.file_utils import *\n",
    "from pyexplain.benchmark.plot import *\n",
    "from pyexplain.benchmark.check_results import *\n",
    "import IPython\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyexplain.examples.utils import *\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['font.weight']= 'bold'\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:85% !important; }</style>\"))\n",
    "\n",
    "# MAC\n",
    "environment = 'MAC'\n",
    "BASE_MAC_LINUX = {\n",
    "    'MAC': '/Users/emiliogamba/Documents/01_VUB/01_Research/01_Shared_Projects/',\n",
    "    'LINUX': '/home/emilio/research/'\n",
    "}\n",
    "\n",
    "PATH_FIGURES_POST_PAPER = Path(BASE_MAC_LINUX[environment]) / \"01_holygrail/latex/journal/jair21/figures/\"\n",
    "EXPERIMENT_RESULTS = Path(BASE_MAC_LINUX[environment]) / \"06_HPC_Experiments/experiments/data/output/\"\n",
    "BASE_OUTPUT_PATH = BASE_MAC_LINUX[environment] + \"06_HPC_Experiments/experiments/data/output/\"\n",
    "REMOTE_EXPERIMENT_RESULTS = \"/data/brussel/101/vsc10143/hpc_experiments2/experiments/data/output/\"\n",
    "OCUS_EXPLAIN_EXAMPLES = Path(BASE_MAC_LINUX[environment] + \"05_OCUS_Explain/code/pyexplain/examples/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ef0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_KILLER_INSTANCES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25398301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_grows = pd.read_pickle(\"/Users/emiliogamba/Documents/01_VUB/01_Research/01_Shared_Projects/06_HPC_Experiments/jair/jair_rq2_all_grows.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12754eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mus = pd.read_pickle(\"/Users/emiliogamba/Documents/01_VUB/01_Research/01_Shared_Projects/06_HPC_Experiments/jair/jair_rq2_mus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e8d75",
   "metadata": {},
   "source": [
    "# RQ2 Which domain specific grow improve the overall runtime?\n",
    "\n",
    "using the cumulative runtime computed directly for the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_grows[\n",
    "    (df_all_grows[\"params_instance\"].str.contains(\"sudoku-easy\")) &\n",
    "    (df_all_grows[\"params_grow_config\"] == \"SUBSETMAX SAT MCSes + Actual + Unif.\") &\n",
    "    (df_all_grows[\"explanation config\"] == \"OUS Iter.+Lit. Incr. HS\")\n",
    "][[\"params_instance\", \"time_totalTime\", \"time_to_first_expl\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55312f6",
   "metadata": {},
   "source": [
    "# Incremental vs non-incremental runtime plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = len(set(df_all_grows[\"params_instance\"]))\n",
    "\n",
    "for id, row in df_all_grows[\n",
    "                    [\"explanation config\", \"params_grow_config\", \"time_totalTime\"]\n",
    "                ].groupby(by=[\"explanation config\", \"params_grow_config\"]).count().iterrows():\n",
    "    assert row[\"time_totalTime\"] == num_instances, f'Num instances for config {row[\"explanation config\"]} - {row[\"params_grow_config\"]}: expected = {num_instances} got {row[\"time_totalTime\"]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66595624",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_grow = 'SAT'\n",
    "# grow = 'SAT MCSes + Actual + Unif.'\n",
    "# fixing the grow: sat correction subset enumeration\n",
    "df_sat_corr_grow = df_all_grows[\n",
    "    df_all_grows[\"params_grow_config\"] == sat_grow\n",
    "]\n",
    "# display(df_all_grows[\"time_totalTime\"])\n",
    "\n",
    "mapping_expl_config_incremental = {\n",
    "    'OCUS': 'OCUS+Incr. HS',\n",
    "    'OUS Iter.': 'OUS Iter.+Lit. Incr. HS',\n",
    "    'OUSb': 'OUSb+Lit. Incr. HS'\n",
    "}\n",
    "\n",
    "label_mapping_expl_config = {\n",
    "    'OCUS': 'OCUS',\n",
    "    'OUS Iter.': 'OCUS\\_Split',\n",
    "    'OUSb': 'OCUS\\_Bounded'\n",
    "}\n",
    "\n",
    "color_matching = {\n",
    "    'OCUS': 'cornflowerblue',\n",
    "    'OUS Iter.': 'tab:orange',\n",
    "    'OUS Iter.+Lit. Incr. HS': 'tab:red',\n",
    "    'OUSb': 'forestgreen',\n",
    "    'MUS': 'tab:brown',\n",
    "    'OUSb+Lit. Incr. HS': 'forestgreen',\n",
    "    'OCUS+Incr. HS': 'tab:blue'\n",
    "}\n",
    "\n",
    "\n",
    "all_instances = set(df_sat_corr_grow[\"params_instance\"])\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "all_worse_instances = set()\n",
    "\n",
    "for non_incremental_config, incremental_config in mapping_expl_config_incremental.items():\n",
    "    non_incremental_times = []\n",
    "    incremental_times = []\n",
    "    for instance in all_instances:\n",
    "        incremental_runtime = df_sat_corr_grow[\n",
    "            (df_sat_corr_grow[\"params_instance\"] == instance) &\n",
    "            (df_sat_corr_grow[\"explanation config\"] == incremental_config)\n",
    "        ][\"time_totalTime\"]\n",
    "                \n",
    "        non_incremental_runtime = df_sat_corr_grow[\n",
    "            (df_sat_corr_grow[\"params_instance\"] == instance) &\n",
    "            (df_sat_corr_grow[\"explanation config\"] == non_incremental_config)\n",
    "        ][\"time_totalTime\"]\n",
    "\n",
    "        incremental_times.append(float(incremental_runtime))\n",
    "        non_incremental_times.append(float(non_incremental_runtime))\n",
    "        \n",
    "        assert len(incremental_runtime) == 1, \"Incremnetal time empty\"\n",
    "        assert len(non_incremental_runtime) == 1, \"Non-Incremnetal time empty\"\n",
    "        \n",
    "        if float(incremental_runtime) > float(non_incremental_runtime) and incremental_config == \"OUS Iter.+Lit. Incr. HS\":\n",
    "            print(f\"{incremental_config=} \\t{instance} - {float(incremental_runtime)} s\") \n",
    "            print(f\"{non_incremental_config=} \\t{instance} - {float(non_incremental_runtime)} s\") \n",
    "            all_worse_instances.add(instance)\n",
    "        \n",
    "    plt.scatter(\n",
    "        incremental_times, \n",
    "        non_incremental_times, \n",
    "        marker='+',\n",
    "        label=label_mapping_expl_config[non_incremental_config],\n",
    "        color=color_matching[incremental_config]\n",
    "    )\n",
    "\n",
    "plt.plot(range(1, 4000, 100), range(1, 4000, 100), '-', color='black')\n",
    "plt.xlim([1, 4000]);plt.ylim([1, 4000])\n",
    "plt.xscale('log');plt.yscale('log')\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Incremental OCUS - time (s)', fontsize=22); plt.ylabel('Non-incremental OCUS - time (s)', fontsize=20)\n",
    "plt.xticks(fontsize=20); plt.yticks(fontsize=22)\n",
    "\n",
    "\n",
    "filepath = PATH_FIGURES_POST_PAPER / \"incremental\" / datetime.now().strftime(f\"incremental_vs_non_{sat_grow}_%Y_%m_%d.pdf\")\n",
    "print(filepath)\n",
    "plt.savefig(\n",
    "    PATH_FIGURES_POST_PAPER / \"incremental\" / datetime.now().strftime(f\"incremental_vs_non_{sat_grow}_%Y_%m_%d.pdf\"),bbox_inches =\"tight\",\n",
    "            transparent = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07f93a",
   "metadata": {},
   "source": [
    "# Correction Subset Enumeraiton strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7210bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_grows = [\n",
    " 'SUBSETMAX SAT MCSes + Final + Unif.',\n",
    " 'SUBSETMAX SAT MCSes + Full + Unif.',\n",
    " 'SUBSETMAX SAT MCSes + Initial + Unif.',\n",
    "    'Greedy MCSes + Actual + Unif.'\n",
    "    \n",
    "# 'Greedy-Sat + Final + Unif.',\n",
    " #'Greedy-Sat + Full + Unif.',\n",
    " #'Greedy-Sat + Initial + Unif.',\n",
    "]\n",
    "\n",
    "grow_renaming =  {\n",
    "    'MaxSAT + Actual + Unif.': 'Single Dom.-spec. MaxSAT',\n",
    "    'MaxSAT + Full + Unif.': 'Single MaxSAT Full',\n",
    "\n",
    "    'SAT': 'Single SAT',\n",
    "\n",
    "    'Greedy MCSes + Actual + Unif.': 'Dom.-spec. MaxSAT+Multi SAT',\n",
    "\n",
    "    'Disj.MCSes + Actual + Unif.': 'Multi Dom.-spec.MaxSAT',\n",
    "\n",
    "    'SAT MCSes + Actual + Unif.': \"Multi SAT\",\n",
    "\n",
    "    'SUBSETMAX SAT MCSes + Actual + Unif.': \"Multi SubsetMax-SAT\",\n",
    "    'SUBSETMAX SAT MCSes + Final + Unif.': \"Multi SubsetMax-SAT.-Final\",\n",
    "    'SUBSETMAX SAT MCSes + Full + Unif.': \"Multi SubsetMax SAT.-Full\",\n",
    "    'SUBSETMAX SAT MCSes + Initial + Unif.': \"Multi SubsetMax-SAT.-Initial\",\n",
    "\n",
    "    'Greedy-Sat + Actual + Unif.': 'Single SubsetMax-SAT',\n",
    "    'Greedy-Sat + Final + Unif.': 'Single SubsetMax-SAT-Final',\n",
    "    'Greedy-Sat + Full + Unif.': 'Single SubsetMax-SAT-Full',\n",
    "    'Greedy-Sat + Initial + Unif.': 'Single SubsetMaxSAT-Initial',\n",
    "    \n",
    "    \"MUS\": 'MUS'\n",
    "}\n",
    "\n",
    "## PUT MUS ALWAYS AS BOTTOM ON LEGEND\n",
    "grow_sorted_ordering = [\n",
    "    'OUSb',\n",
    "    'OUSb+Lit. Incr. HS',\n",
    "    'OCUS',\n",
    "    'OCUS+Incr. HS',\n",
    "    'OUS Iter.',\n",
    "    'OUS Iter.+Lit. Incr. HS',\n",
    "    'MUS',\n",
    "]\n",
    "\n",
    "color_matching = {\n",
    "    'OCUS': 'cornflowerblue',\n",
    "    'OUS Iter.': 'tab:orange',\n",
    "    'OUS Iter.+Lit. Incr. HS': 'tab:red',\n",
    "    'OUSb': 'forestgreen',\n",
    "    'MUS': 'tab:brown',\n",
    "    'OUSb+Lit. Incr. HS': 'forestgreen',\n",
    "    'OCUS+Incr. HS': 'tab:blue'\n",
    "}\n",
    "\n",
    "epxl_conf_renaming = {\n",
    "    'OCUS': 'OCUS',\n",
    "    'OUS Iter.': 'OCUS\\_Split',\n",
    "    'OUS Iter.+Lit. Incr. HS': 'OCUS\\_Split+Incr.',\n",
    "    'OUSb': 'OCUS\\_Bounded',\n",
    "    'MUS': 'MUS',\n",
    "    'OUSb+Lit. Incr. HS': 'OCUS\\_Bounded+Incr.',\n",
    "    'OCUS+Incr. HS': 'OCUS+Incr.'\n",
    "}\n",
    "\n",
    "\n",
    "conf_title = {\n",
    "    \"OUS Iter.+Lit. Incr. HS\": \"Expl.-Spec. OCUS+Incr.\",\n",
    "    \"OCUS\": \"OCUS\",\n",
    "    \"OUS Iter.\": \"Expl.-Spec. OCUS\",\n",
    "    \"OCUS+Incr. HS\": \"OCUS+Incr.\",\n",
    "    \"OUSb\": \"Bounded OUS\",\n",
    "    \"OUSb+Lit. Incr. HS\": \"Bounded OUS+Incr.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f90d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "color_matching = {\n",
    "    'OCUS': 'tab:blue',\n",
    "    'OUS Iter.': 'tab:red',\n",
    "    'OUS Iter.+Lit. Incr. HS': 'tab:red',\n",
    "    'OUSb': 'forestgreen',\n",
    "    'MUS': 'tab:brown',\n",
    "    'OUSb+Lit. Incr. HS': 'forestgreen',\n",
    "    'OCUS+Incr. HS': 'tab:blue'\n",
    "}\n",
    "\n",
    "### MUS Time to explain instances\n",
    "mus_time_instances = sorted(list(df_all_grows[\n",
    "    (df_all_grows[\"time_timedout\"] == 0) & \n",
    "    (df_all_grows[\"explanation config\"] == \"MUS\")\n",
    "][\"time_totalTime\"]))\n",
    "\n",
    "## COMPUTING ORDERING FOR ALL CONFIGS - \"Greedy MCSes + Actual + Unif.\" as best grow\n",
    "grow_config_timings = []\n",
    "\n",
    "for conf in set(df_all_grows[\"explanation config\"]):\n",
    "    if conf == \"MUS\": continue\n",
    "    time_instances = sorted(list(df_all_grows[\n",
    "            (df_all_grows[\"time_timedout\"] == 0) & \n",
    "            (df_all_grows[\"params_grow_config\"] == \"Greedy MCSes + Actual + Unif.\") &\n",
    "            (df_all_grows[\"explanation config\"] == conf)\n",
    "        ][\"time_totalTime\"]))\n",
    "    \n",
    "    grow_config_timings.append((conf, len(time_instances), max([10**8] + time_instances), time_instances))\n",
    "\n",
    "\n",
    "\n",
    "for grow in set(df_all_grows[\"params_grow_config\"]) - set(ignored_grows):\n",
    "        \n",
    "    grow_timings = {\n",
    "        \"MUS\": (\n",
    "            len(mus_time_instances), \n",
    "            max([1000000000] + mus_time_instances), \n",
    "            mus_time_instances\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    \n",
    "    ## select \n",
    "    df_selected_grow = df_all_grows[df_all_grows[\"params_grow_config\"] == grow]\n",
    "    for conf in set(df_selected_grow[\"explanation config\"]):\n",
    "        if conf == \"MUS\": continue\n",
    "        \n",
    "        time_instances = sorted(list(df_selected_grow[\n",
    "            (df_selected_grow[\"time_timedout\"] == 0) & \n",
    "            (df_selected_grow[\"explanation config\"] == conf)\n",
    "        ][\"time_totalTime\"]))\n",
    "        \n",
    "        if len(time_instances) == 0: continue\n",
    "        \n",
    "        grow_timings[conf] = (len(time_instances), max([1000000000] + time_instances), time_instances)\n",
    "\n",
    "    \n",
    "    ### BUILDING FIGURE\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(9, 6))\n",
    "    for conf in grow_sorted_ordering:\n",
    "        if conf not in grow_timings: continue\n",
    "\n",
    "        _,_, time_instances = grow_timings[conf]\n",
    "        if 'Incr' in conf:\n",
    "            plt.plot(\n",
    "                range(1, len(time_instances)+1), \n",
    "                time_instances, \n",
    "                label=epxl_conf_renaming[conf], \n",
    "                linewidth=2.5, \n",
    "                color=color_matching[conf]\n",
    "            )\n",
    "        else:\n",
    "            plt.plot(\n",
    "                range(1, len(time_instances)+1), \n",
    "                time_instances, \n",
    "                '-.', \n",
    "                label=epxl_conf_renaming[conf], \n",
    "                linewidth=2.25, \n",
    "                color=color_matching[conf]\n",
    "            )\n",
    "    \n",
    "    plt.legend(fontsize=18, loc='center left', bbox_to_anchor=(1.0, 0.55))\n",
    "    #plt.title(grow_renaming[grow])\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.ylim([1, 4000])\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.ylabel(\"Time (s)\",fontsize=24)\n",
    "    plt.xlabel(\"Number of instances solved\",fontsize=24)\n",
    "    output_filename = str(PATH_FIGURES_POST_PAPER / \"grow\" / f\"{datetime.now().strftime(f'rq3_cactus_r_%Y_%m_%d')}_{grow.replace(' ', '_').replace('+', '')}.pdf\")\n",
    "    print(output_filename)\n",
    "    plt.savefig(output_filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99987869",
   "metadata": {},
   "source": [
    "# Effect of the grow method on incrementality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_grows[\n",
    "    (df_all_grows[\"time_timedout\"]) &\n",
    "    (df_all_grows[\"params_instance\"].str.contains(\"sudoku\")) &\n",
    "    (~df_all_grows[\"params_instance\"].str.contains(\"wiki\")) &\n",
    "    (~df_all_grows[\"params_instance\"].str.contains(\"killer\"))\n",
    "    #df_all_grows[\"params_explanation_computer\"].str.contains(\"OCUS\")\n",
    "][\n",
    "    [\"params_instance\", \"tot_lits_derived\", \"time_timedout\"]\n",
    "].sort_values(\n",
    "    by=[\"params_instance\", \"tot_lits_derived\"], \n",
    "    ascending=[True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df_all_grows[\"params_grow_config\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa3758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ignored_grow_configurations = [\n",
    "    'Disj.MCSes + Full + Unif.',\n",
    "    # 'Greedy MCSes + Full + Unif.' ,\n",
    "    'No Grow',\n",
    "    'SUBSETMAX SAT MCSes + Final + Unif.',\n",
    "    'SUBSETMAX SAT MCSes + Full + Unif.',\n",
    "    'SUBSETMAX SAT MCSes + Initial + Unif.',\n",
    "    'Greedy-Sat + Final + Unif.',\n",
    "    'Greedy-Sat + Full + Unif.',\n",
    "    'Greedy-Sat + Initial + Unif.',\n",
    "    'Greedy MCSes + Actual + Unif.'\n",
    "]\n",
    "\n",
    "\n",
    "selected_grow_configurations = [\n",
    "    c for c in set(df_all_grows[\"params_grow_config\"]) if c not in ignored_grow_configurations\n",
    "]\n",
    "\n",
    "select_explanation_configs = list(set(df_all_grows[\"explanation config\"]))\n",
    "\n",
    "mus_time_instances = time_instances = sorted(list(df_all_grows[\n",
    "    (~df_all_grows[\"time_timedout\"]) & \n",
    "    (df_all_grows[\"explanation config\"] == \"MUS\")\n",
    "][\"time_totalTime\"]))\n",
    "\n",
    "## COMPUTING ORDERING FOR ALL CONFIGS - \"Greedy MCSes + Actual + Unif.\" as best grow\n",
    "grow_config_timings = []\n",
    "\n",
    "for grow in selected_grow_configurations:\n",
    "    if grow == \"MUS\": continue\n",
    "    time_instances = sorted(list(df_all_grows[\n",
    "            (~df_all_grows[\"time_timedout\"]) & \n",
    "            (df_all_grows[\"params_grow_config\"] == grow) &\n",
    "            (df_all_grows[\"explanation config\"] == \"OUS Iter.+Lit. Incr. HS\")\n",
    "        ][\"time_totalTime\"]))\n",
    "    \n",
    "    grow_config_timings.append((grow, len(time_instances), max([10**8] + time_instances), time_instances))\n",
    "\n",
    "## PUT MUS ALWAYS AS BOTTOM ON LEGEND\n",
    "grow_sorted_ordering = [\n",
    "\t\"SAT\",\n",
    "    \"MaxSAT + Actual + Unif.\",\n",
    "\t\"MaxSAT + Full + Unif.\",\n",
    "    'Greedy-Sat + Final + Unif.',\n",
    "    'Greedy-Sat + Full + Unif.',\n",
    "    'Greedy-Sat + Initial + Unif.',\n",
    "\t\"Greedy-Sat + Actual + Unif.\",\n",
    "    \"Disj.MCSes + Actual + Unif.\",\n",
    "\t\"Greedy MCSes + Actual + Unif.\",\n",
    "\t\"SUBSETMAX SAT MCSes + Actual + Unif.\",\n",
    "\t\"SUBSETMAX SAT MCSes + Full + Unif.\",\n",
    "\t\"SUBSETMAX SAT MCSes + Initial + Unif.\",\n",
    "\t\"SUBSETMAX SAT MCSes + Final + Unif.\",\n",
    "    'SAT MCSes + Actual + Unif.',\n",
    "    \"MUS\",\n",
    "]\n",
    "\n",
    "for conf in select_explanation_configs:\n",
    "    if conf == \"MUS\": continue\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    \n",
    "    explanation_timing = {\n",
    "        \"MUS\": (len(mus_time_instances), max([1000000000] + mus_time_instances), mus_time_instances)\n",
    "    }\n",
    "    print(\"selected_grow_configurations:\")\n",
    "    for grow in selected_grow_configurations:\n",
    "        print(\"\\t\", conf, grow)\n",
    "        #\n",
    "        if grow == \"MUS\": continue\n",
    "\n",
    "        time_instances = sorted(list(df_all_grows[\n",
    "            (~df_all_grows[\"time_timedout\"]) & \n",
    "            (df_all_grows[\"params_grow_config\"] == grow) &\n",
    "            (df_all_grows[\"explanation config\"] == conf)\n",
    "        ][\"time_totalTime\"]))\n",
    "        print(\"\\t\", grow, len(time_instances))\n",
    "        \n",
    "        if len(time_instances) == 0: continue\n",
    "        explanation_timing[grow] = (len(time_instances), max([1000000000] + time_instances), time_instances)\n",
    "\n",
    "    base_grows = ['Dom.-spec. MaxSAT', 'MaxSAT Full', 'No grow']\n",
    "    print(list(explanation_timing))\n",
    "    print(\"grow_sorted_ordering:\")\n",
    "    for grow in grow_sorted_ordering:\n",
    "        print(\"\\t\", conf, grow)\n",
    "        if grow not in explanation_timing: continue\n",
    "        \n",
    "        _,_, time_instances = explanation_timing[grow]\n",
    "        renamed_grow = grow_renaming[grow] if (grow in grow_renaming) else grow\n",
    "        if renamed_grow == \"MUS\" or renamed_grow in base_grows:\n",
    "            plt.plot(range(1, len(time_instances)+1), time_instances, '-.', label=renamed_grow, linewidth=2)\n",
    "        else:\n",
    "            plt.plot(range(1, len(time_instances)+1), time_instances, label=renamed_grow, linewidth=2)\n",
    "#     plt.legend(fontsize=18, loc='lower right')#\n",
    "    if conf == \"OCUS+Incr. HS\":\n",
    "        plt.legend(fontsize=20, loc='upper left', bbox_to_anchor=(1.2, 0.95))\n",
    "\n",
    "#     def export_legend(legend, filename=str(PATH_FIGURES_POST_PAPER /\"legend.png\")):\n",
    "#         fig  = legend.figure\n",
    "#         fig.canvas.draw()\n",
    "#         bbox  = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "#         fig.savefig(filename, dpi=\"figure\", bbox_inches=bbox)\n",
    "\n",
    "#     export_legend(\n",
    "#         legend,\n",
    "#         filename=str(PATH_FIGURES_POST_PAPER /f\"legend_{conf.replace(' ', '_').replace('+', '').replace('.','')}.pdf\"))\n",
    "    #TODO: add description outside of plot\n",
    "#     plt.title(f'{conf_title[conf]}',fontsize=22)\n",
    "#     print(conf)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel(\"Time (s)\",fontsize=24)\n",
    "    plt.ylim([1, 10000])\n",
    "    plt.xlabel(\"Number of instances solved\",fontsize=24)\n",
    "    output_filename = str(PATH_FIGURES_POST_PAPER / \"effect_grow_incremental\"/ f\"{datetime.now().strftime(f'rq2_cactus_log_%Y_%m_%d')}_{conf.replace(' ', '_').replace('+', '').replace('.','')}.pdf\")\n",
    "    print(output_filename)\n",
    "    plt.savefig(output_filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e8cc7",
   "metadata": {},
   "source": [
    "## For the best configuration - Corr Subsets - generate cumulative explanation time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857a107",
   "metadata": {},
   "source": [
    "## SUBSETMAX SAT MCSes and MUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ddce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_grows\n",
    "df_mus_all_grows_selected = df_all_grows[\n",
    "    (df_all_grows[\"params_grow_config\"].isin([\"SUBSETMAX SAT MCSes + Actual + Unif.\", \"MUS\"])) & \n",
    "    (~df_all_grows[\"time_timedout\"])\n",
    "]\n",
    "\n",
    "## df_corr_selected\n",
    "# display(df_mus_all_grows_selected.groupby(by=[\"params_explanation_computer\",\"params_grow_config\"]).count())\n",
    "\n",
    "df_corr_selected_grouped = df_mus_all_grows_selected.groupby(by=[\"params_explanation_computer\", \"params_grow_config\"]).agg(\n",
    "    t=(\"tot_time_explain\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    f=(\"time_timedout\", lambda x: f\"[{str(len(x) - np.sum(x)).zfill(3)} / {len(x)}]\"),\n",
    "    avg_opt=(\"%time_opt2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_opt=(\"%time_opt2\" , lambda x: round(np.std(x), 2)),\n",
    "    avg_sat=(\"%time_sat2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_sat=(\"%time_sat2\" ,lambda x: round(np.std(x), 2)),\n",
    "    avg_grow=(\"%time_grow2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_grow=(\"%time_grow2\" , lambda x: round(np.std(x), 2)),\n",
    "    avg_disj_mcs=(\"%time_disj_mcs2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_disj_mcs=(\"%time_disj_mcs2\" , lambda x: round(np.std(x), 2)),\n",
    "    avg_remaining=(\"%time_remaining2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_remaining=(\"%time_remaining2\" , lambda x: round(np.std(x), 2)),\n",
    "    sum_t_opt=(\"tot_time_opt\" , lambda x: sum(x)),\n",
    "    sum_t_sat=(\"tot_time_sat\" , lambda x: sum(x)),\n",
    "    sum_t_grow=(\"tot_time_grow\" , lambda x: sum(x)),\n",
    "    avg_n_opt=(\"tot_n_opt\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    avg_n_sat=(\"tot_n_sat\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    avg_n_grow=(\"tot_n_grow\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    tot_n_opt=(\"tot_n_opt\" , lambda x: sum(x)),\n",
    "    tot_n_sat=(\"tot_n_sat\" , lambda x: sum(x)),\n",
    "    tot_n_grow=(\"tot_n_grow\" , lambda x: sum(x)),\n",
    "    avg_n_hs=(\"tot_n_hs\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    cnt = (\"time_timedout\", \"count\")\n",
    ")\n",
    "\n",
    "df_temp = df_corr_selected_grouped.reset_index()\n",
    "for k in [\"opt\", \"sat\", \"grow\", \"disj_mcs\", \"remaining\"]:\n",
    "    df_temp[k] = df_temp.apply(lambda row: None, axis=1)\n",
    "    df_temp[\"%\"+k] = df_temp.apply(lambda row: None, axis=1)\n",
    "\n",
    "df_temp[\"avg_t_opt\"] = df_temp.apply(\n",
    "    lambda row: round(row[\"sum_t_opt\"]/row['tot_n_opt'], 4) if row[\"tot_n_opt\"] !=0 else 0, axis=1)\n",
    "df_temp[\"avg_t_sat\"] = df_temp.apply(\n",
    "    lambda row: round(row['sum_t_sat']/row['tot_n_sat']  if row[\"tot_n_sat\"] !=0 else 0, 4), axis=1)\n",
    "df_temp[\"avg_t_grow\"] = df_temp.apply(\n",
    "    lambda row: round(row['sum_t_grow']/row['tot_n_grow']  if row[\"tot_n_grow\"] !=0 else 0, 4), axis=1)\n",
    "\n",
    "for index,row in df_temp.iterrows():\n",
    "    for k in [\"opt\", \"sat\", \"grow\", \"disj_mcs\", \"remaining\"]:\n",
    "        df_temp.at[index,k]= f'{row[\"avg_\"+k]}% [+/- {row[\"std_\"+k]}%]'\n",
    "        df_temp.at[index,\"%\"+k]= f'{row[\"avg_\"+k]}%'\n",
    "\n",
    "renaming_expl_config = {\n",
    "    \"MUS\": \"MUS\",\n",
    "    \"OCUS\":\"OCUS+Incr. HS\",\n",
    "    \"OCUS_NOT_INCREMENTAL\":\"OCUS\",\n",
    "    \"OUS_INCREMENTAL_NAIVE\":\"OUSb+Lit. Incr. HS\",\n",
    "    \"OUS_INCREMENTAL_NAIVE_PARALLEL\": \"OUS Iter.+Lit. Incr. HS\",\n",
    "    \"OUS_NAIVE_PARALLEL\":\"OUS Iter.\",\n",
    "    \"OUS_SS\": \"OUSb\"\n",
    "}\n",
    "        \n",
    "df_temp[\"expl_config\"] = df_temp.apply(\n",
    "    lambda row: renaming_expl_config[row['params_explanation_computer']], axis=1)\n",
    "\n",
    "percentage_exec_time_ous = df_temp[\n",
    "        df_temp[\"expl_config\"] != \"bla\"\n",
    "    ][\n",
    "    [\"expl_config\",#'params_grow_config',\n",
    "     \"t\",\n",
    "     \"f\",\n",
    "     \"%opt\", \n",
    "     \"%sat\", \n",
    "     \"%grow\", \n",
    "     \"%disj_mcs\",\n",
    "     #\"%remaining\",\n",
    "     \"avg_n_hs\"\n",
    "     #'avg_t_opt', \n",
    "     #'avg_n_opt', \n",
    "     #'avg_t_sat',\n",
    "     #'avg_n_sat', \n",
    "     #'avg_t_grow',\n",
    "     #'avg_n_grow'\n",
    "    ]].sort_values([\"avg_n_hs\"], ascending=[False])\n",
    "display(percentage_exec_time_ous)\n",
    "print(percentage_exec_time_ous.to_latex(index=False))\n",
    "\n",
    "# df_sat_ignored_instances.groupby(by=[\"params_explanation_computer\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b9dec",
   "metadata": {},
   "source": [
    "## Subset max SAT grow and MUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eba674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_grows\n",
    "df_mus_all_grows_selected = df_all_grows[\n",
    "    (df_all_grows[\"params_grow_config\"].isin([\"Greedy-Sat + Actual + Unif.\", \"MUS\"])) & \n",
    "    (~df_all_grows[\"time_timedout\"])\n",
    "]\n",
    "\n",
    "## df_corr_selected\n",
    "# display(df_mus_all_grows_selected.groupby(by=[\"params_explanation_computer\",\"params_grow_config\"]).count())\n",
    "\n",
    "df_corr_selected_grouped = df_mus_all_grows_selected.groupby(by=[\"params_explanation_computer\", \"params_grow_config\"]).agg(\n",
    "    t=(\"tot_time_explain\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    f=(\"time_timedout\", lambda x: f\"[{str(len(x) - np.sum(x)).zfill(3)} / {len(x)}]\"),\n",
    "    avg_opt=(\"%time_opt2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_opt=(\"%time_opt2\" , lambda x: round(np.std(x), 2)),\n",
    "    avg_sat=(\"%time_sat2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_sat=(\"%time_sat2\" ,lambda x: round(np.std(x), 2)),\n",
    "    avg_grow=(\"%time_grow2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_grow=(\"%time_grow2\" , lambda x: round(np.std(x), 2)),\n",
    "    avg_disj_mcs=(\"%time_disj_mcs2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_disj_mcs=(\"%time_disj_mcs2\" , lambda x: round(np.std(x), 2)),\n",
    "    avg_remaining=(\"%time_remaining2\" , lambda x: round(mean_ignore_zeros(x), 2)),\n",
    "    std_remaining=(\"%time_remaining2\" , lambda x: round(np.std(x), 2)),\n",
    "    sum_t_opt=(\"tot_time_opt\" , lambda x: sum(x)),\n",
    "    sum_t_sat=(\"tot_time_sat\" , lambda x: sum(x)),\n",
    "    sum_t_grow=(\"tot_time_grow\" , lambda x: sum(x)),\n",
    "    avg_n_opt=(\"tot_n_opt\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    avg_n_sat=(\"tot_n_sat\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    avg_n_grow=(\"tot_n_grow\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    tot_n_opt=(\"tot_n_opt\" , lambda x: sum(x)),\n",
    "    tot_n_sat=(\"tot_n_sat\" , lambda x: sum(x)),\n",
    "    tot_n_grow=(\"tot_n_grow\" , lambda x: sum(x)),\n",
    "    avg_n_hs=(\"tot_n_hs\" , lambda x: round(mean_ignore_zeros(x))),\n",
    "    cnt = (\"time_timedout\", \"count\")\n",
    ")\n",
    "\n",
    "df_temp = df_corr_selected_grouped.reset_index()\n",
    "for k in [\"opt\", \"sat\", \"grow\", \"disj_mcs\", \"remaining\"]:\n",
    "    df_temp[k] = df_temp.apply(lambda row: None, axis=1)\n",
    "    df_temp[\"%\"+k] = df_temp.apply(lambda row: None, axis=1)\n",
    "\n",
    "df_temp[\"avg_t_opt\"] = df_temp.apply(\n",
    "    lambda row: round(row[\"sum_t_opt\"]/row['tot_n_opt'], 4) if row[\"tot_n_opt\"] !=0 else 0, axis=1)\n",
    "df_temp[\"avg_t_sat\"] = df_temp.apply(\n",
    "    lambda row: round(row['sum_t_sat']/row['tot_n_sat']  if row[\"tot_n_sat\"] !=0 else 0, 4), axis=1)\n",
    "df_temp[\"avg_t_grow\"] = df_temp.apply(\n",
    "    lambda row: round(row['sum_t_grow']/row['tot_n_grow']  if row[\"tot_n_grow\"] !=0 else 0, 4), axis=1)\n",
    "\n",
    "for index,row in df_temp.iterrows():\n",
    "    for k in [\"opt\", \"sat\", \"grow\", \"disj_mcs\", \"remaining\"]:\n",
    "        df_temp.at[index,k]= f'{row[\"avg_\"+k]}% [+/- {row[\"std_\"+k]}%]'\n",
    "        df_temp.at[index,\"%\"+k]= f'{row[\"avg_\"+k]}%'\n",
    "\n",
    "renaming_expl_config = {\n",
    "    \"MUS\": \"MUS\",\n",
    "    \"OCUS\":\"OCUS+Incr. HS\",\n",
    "    \"OCUS_NOT_INCREMENTAL\":\"OCUS\",\n",
    "    \"OUS_INCREMENTAL_NAIVE\":\"OUSb+Lit. Incr. HS\",\n",
    "    \"OUS_INCREMENTAL_NAIVE_PARALLEL\": \"OUS Iter.+Lit. Incr. HS\",\n",
    "    \"OUS_NAIVE_PARALLEL\":\"OUS Iter.\",\n",
    "    \"OUS_SS\": \"OUSb\"\n",
    "}\n",
    "        \n",
    "df_temp[\"expl_config\"] = df_temp.apply(\n",
    "    lambda row: renaming_expl_config[row['params_explanation_computer']], axis=1)\n",
    "\n",
    "percentage_exec_time_ous = df_temp[\n",
    "        df_temp[\"expl_config\"] != \"bla\"\n",
    "    ][\n",
    "    [\"expl_config\",#'params_grow_config',\n",
    "     \"t\",\n",
    "     \"f\",\n",
    "     \"%opt\", \n",
    "     \"%sat\", \n",
    "     \"%grow\", \n",
    "     \"%disj_mcs\",\n",
    "     #\"%remaining\",\n",
    "     \"avg_n_hs\"\n",
    "     #'avg_t_opt', \n",
    "     #'avg_n_opt', \n",
    "     #'avg_t_sat',\n",
    "     #'avg_n_sat', \n",
    "     #'avg_t_grow',\n",
    "     #'avg_n_grow'\n",
    "    ]].sort_values([\"avg_n_hs\"], ascending=[False])\n",
    "display(percentage_exec_time_ous)\n",
    "print(percentage_exec_time_ous.to_latex(index=False))\n",
    "\n",
    "# df_sat_ignored_instances.groupby(by=[\"params_explanation_computer\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645d0d9",
   "metadata": {},
   "source": [
    "## RQ4: What is the efficiency of a single step O(C)US and is single step sufficiently efficient for an interactive context?\n",
    "\n",
    "### RQ4a) Time to first explanation and average time to explain for subsetmax ___sat correction subsets___\n",
    "\n",
    "Ingoring the timedout instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8825fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greedy_corr =  df_all_grows[\n",
    "    #(df_all_grows[\"params_grow_config\"] == \"SUBSETMAX SAT MCSes + Actual + Unif.\")\n",
    "    (df_all_grows[\"params_grow_config\"] == \"Greedy MCSes + Actual + Unif.\")   \n",
    "]\n",
    "\n",
    "grouped_params_instance_summed_incremental = df_greedy_corr.groupby(\n",
    "    by=[\"params_instance\"]\n",
    ").sum().reset_index()\n",
    "\n",
    "# non_timedout_instances_incremental = set(df_corr_enh[\"params_instance\"])\n",
    "non_timedout_instances_incremental = grouped_params_instance_summed_incremental[\n",
    "    grouped_params_instance_summed_incremental[\"time_timedout\"] == 0\n",
    "][\"params_instance\"].to_list()\n",
    "\n",
    "df_greedy_corr_incremental_non_timeout = df_greedy_corr[\n",
    "    df_greedy_corr[\"params_instance\"].isin(non_timedout_instances_incremental)\n",
    "]\n",
    "\n",
    "grouped_greedy_corr_configs = df_greedy_corr_incremental_non_timeout.groupby(\n",
    "    by=[\"explanation config\"]\n",
    ").agg(\n",
    "    t_expl=(\"time_explain\", sum),\n",
    "    t_avg_first_expl=(\"time_to_first_expl\", lambda x: round(np.mean(x), 2)),\n",
    "    cnt=(\"time_explain\", \"count\"),\n",
    "    tot_time=(\"tot_time_explain\", np.sum)\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "df_incr_configs_indiv_expls = stats_expls_times(\n",
    "    grouped_greedy_corr_configs[\n",
    "        [\n",
    "            \"explanation config\", \n",
    "            \"t_expl\", \n",
    "            \"t_avg_first_expl\",\n",
    "            \"tot_time\"]\n",
    "    ].copy(deep=True)\n",
    ")\n",
    "\n",
    "ignored = [\n",
    "    \"t_expl\",\n",
    "    \"med_t_expl\",\n",
    "    \"n_expl\",\n",
    "    \"min_t_expl\",\n",
    "    \"max_t_expl\",\n",
    "    \"corr_explanation_config\",\n",
    "    \"tot_time\"\n",
    "]\n",
    "all_cols = [column for column in df_incr_configs_indiv_expls.columns if column not in ignored]+[\"tot_time\"]\n",
    "df_indiv_expls_table = df_incr_configs_indiv_expls[\n",
    "    [\n",
    "        \"explanation config\", \n",
    "        #\"t_avg\",\n",
    "        \"t_avg_first_expl\",\n",
    "        \"avg_t_expl\", \n",
    "        \"q_25\", \n",
    "        \"q_50\", \n",
    "        \"q_75\", \n",
    "        \"q_95\", \n",
    "        \"q_98\", \n",
    "        \"q_100\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "display(df_indiv_expls_table)\n",
    "print(df_indiv_expls_table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ce9b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### All instances where the incremental version performs worse that the non-incremnetal\n",
    "\n",
    "df_sat_grow_corr =  df_all_grows[\n",
    "    #(df_all_grows[\"params_grow_config\"] == \"SUBSETMAX SAT MCSes + Actual + Unif.\")\n",
    "    (df_all_grows[\"params_grow_config\"] == 'SAT') &\n",
    "    (df_all_grows[\"params_instance\"].isin(all_worse_instances))\n",
    "]\n",
    "\n",
    "print(df_all_grows[\"time_to_first_expl\"])\n",
    "print(df_sat_grow_corr[\"time_to_first_expl\"])\n",
    "\n",
    "grouped_params_instance_summed_incremental = df_sat_grow_corr.groupby(\n",
    "    by=[\"params_instance\"]\n",
    ").sum().reset_index()\n",
    "\n",
    "# non_timedout_instances_incremental = set(df_corr_enh[\"params_instance\"])\n",
    "non_timedout_instances_incremental = grouped_params_instance_summed_incremental[\n",
    "    grouped_params_instance_summed_incremental[\"time_timedout\"] == 0\n",
    "][\"params_instance\"].to_list()\n",
    "\n",
    "df_sat_grow_corr_incremental_non_timeout = df_sat_grow_corr[\n",
    "    df_sat_grow_corr[\"params_instance\"].isin(non_timedout_instances_incremental)\n",
    "]\n",
    "\n",
    "grouped_sat_grow_corr_configs = df_sat_grow_corr_incremental_non_timeout.groupby(\n",
    "    by=[\"explanation config\"]\n",
    ").agg(\n",
    "    t_expl=(\"time_explain\", sum),\n",
    "    t_avg_first_expl=(\"time_to_first_expl\", lambda x: round(np.mean(x), 2)),\n",
    "    cnt=(\"time_explain\", \"count\"),\n",
    "    tot_time=(\"tot_time_explain\", np.sum)\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "display(grouped_sat_grow_corr_configs)\n",
    "\n",
    "df_incr_configs_indiv_expls = stats_expls_times(\n",
    "    grouped_sat_grow_corr_configs[\n",
    "        [\n",
    "            \"explanation config\", \n",
    "            \"t_expl\", \n",
    "            \"t_avg_first_expl\",\n",
    "            \"tot_time\"]\n",
    "    ].copy(deep=True)\n",
    ")\n",
    "\n",
    "ignored = [\n",
    "    \"t_expl\",\n",
    "    \"med_t_expl\",\n",
    "    \"n_expl\",\n",
    "    \"min_t_expl\",\n",
    "    \"max_t_expl\",\n",
    "    \"corr_explanation_config\",\n",
    "    \"tot_time\"\n",
    "]\n",
    "all_cols = [column for column in df_incr_configs_indiv_expls.columns if column not in ignored]+[\"tot_time\"]\n",
    "df_indiv_expls_table = df_incr_configs_indiv_expls[\n",
    "    [\n",
    "        \"explanation config\", \n",
    "        #\"t_avg\",\n",
    "        \"t_avg_first_expl\",\n",
    "        \"avg_t_expl\", \n",
    "        \"q_25\", \n",
    "        \"q_50\", \n",
    "        \"q_75\", \n",
    "        \"q_95\", \n",
    "        \"q_98\", \n",
    "        \"q_100\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "display(df_indiv_expls_table)\n",
    "print(df_indiv_expls_table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5f2a3",
   "metadata": {},
   "source": [
    "### RQ4b) Time to first explanation and average time to explain for subsetmax ___sat correction subsets___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### non-timeout instances for all configurations \n",
    "df_non_timeout_instances_subset_max_sat = df_greedy_corr =  df_all_grows[\n",
    "    (df_all_grows[\"params_grow_config\"] == \"SUBSETMAX SAT MCSes + Actual + Unif.\")\n",
    "].groupby([\"params_instance\"]).sum().reset_index()\n",
    "\n",
    "non_timeout_instances_subset_max_sat = df_non_timeout_instances_subset_max_sat[\n",
    "    df_non_timeout_instances_subset_max_sat[\"time_timedout\"] == 0\n",
    "][\"params_instance\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_greedy_corr =  df_all_grows[\n",
    "    (df_all_grows[\"params_grow_config\"] == \"Greedy MCSes + Actual + Unif.\")&\n",
    "\n",
    "    # (df_all_grows[\"params_grow_config\"] == \"SUBSETMAX SAT MCSes + Actual + Unif.\") &\n",
    "    (df_all_grows[\"params_instance\"].isin(non_timeout_instances_subset_max_sat))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "grouped_greedy_corr_configs = df_greedy_corr.groupby(\n",
    "    by=[\"explanation config\"]\n",
    ").agg(\n",
    "    t_expl=(\"time_explain\", sum),\n",
    "    t_avg_first_expl=(\"time_to_first_expl\", lambda x: round(np.mean(x), 2)),\n",
    "    cnt=(\"time_explain\", \"count\"),\n",
    "    tot_time=(\"tot_time_explain\", np.sum)\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "df_incr_configs_indiv_expls = stats_expls_times(\n",
    "    grouped_greedy_corr_configs[\n",
    "        [\n",
    "            \"explanation config\", \n",
    "            \"t_expl\", \n",
    "            \"t_avg_first_expl\",\n",
    "            \"tot_time\"]\n",
    "    ].copy(deep=True)\n",
    ")\n",
    "\n",
    "ignored = [\n",
    "    \"t_expl\",\n",
    "    \"med_t_expl\",\n",
    "    \"n_expl\",\n",
    "    \"min_t_expl\",\n",
    "    \"max_t_expl\",\n",
    "    \"corr_explanation_config\",\n",
    "    \"tot_time\"\n",
    "]\n",
    "all_cols = [column for column in df_incr_configs_indiv_expls.columns if column not in ignored]+[\"tot_time\"]\n",
    "df_indiv_expls_table = df_incr_configs_indiv_expls[\n",
    "    [\n",
    "        \"explanation config\", \n",
    "        #\"t_avg\",\n",
    "        \"t_avg_first_expl\",\n",
    "        \"avg_t_expl\", \n",
    "        \"q_25\", \n",
    "        \"q_50\", \n",
    "        \"q_75\", \n",
    "        \"q_95\", \n",
    "        \"q_98\", \n",
    "        \"q_100\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "display(df_indiv_expls_table)\n",
    "print(df_indiv_expls_table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95929c55",
   "metadata": {},
   "source": [
    "### Average Improvement speed\n",
    "\n",
    "This is sad because there are some isntances where a mus approach is too expensive :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f7a354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_totalTime</th>\n",
       "      <th>time_timeout</th>\n",
       "      <th>time_timedout</th>\n",
       "      <th>time_explain</th>\n",
       "      <th>time_cumul_explain</th>\n",
       "      <th>time_preprocess</th>\n",
       "      <th>time_opt</th>\n",
       "      <th>time_sat</th>\n",
       "      <th>time_grow</th>\n",
       "      <th>time_disj_mcs</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_t_explain</th>\n",
       "      <th>max_t_explain</th>\n",
       "      <th>min_t_explain</th>\n",
       "      <th>n_expls</th>\n",
       "      <th>%time_remaining_ocus</th>\n",
       "      <th>corr_explanation_config</th>\n",
       "      <th>incremental</th>\n",
       "      <th>HS</th>\n",
       "      <th>time_to_first_expl</th>\n",
       "      <th>time_tavg_greedy_explain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explanation config</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MUS</th>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>389</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OUS Iter.+Lit. Incr. HS</th>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>388</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time_totalTime  time_timeout  time_timedout  \\\n",
       "explanation config                                                     \n",
       "MUS                                 403           403            403   \n",
       "OUS Iter.+Lit. Incr. HS             403           403            403   \n",
       "\n",
       "                         time_explain  time_cumul_explain  time_preprocess  \\\n",
       "explanation config                                                           \n",
       "MUS                               403                 403              403   \n",
       "OUS Iter.+Lit. Incr. HS           403                 403              403   \n",
       "\n",
       "                         time_opt  time_sat  time_grow  time_disj_mcs  ...  \\\n",
       "explanation config                                                     ...   \n",
       "MUS                             0         0          0              0  ...   \n",
       "OUS Iter.+Lit. Incr. HS       403       403        403            403  ...   \n",
       "\n",
       "                         avg_t_explain  max_t_explain  min_t_explain  n_expls  \\\n",
       "explanation config                                                              \n",
       "MUS                                389            403            403      403   \n",
       "OUS Iter.+Lit. Incr. HS            388            403            403      403   \n",
       "\n",
       "                         %time_remaining_ocus  corr_explanation_config  \\\n",
       "explanation config                                                       \n",
       "MUS                                       403                      403   \n",
       "OUS Iter.+Lit. Incr. HS                   403                      403   \n",
       "\n",
       "                         incremental   HS  time_to_first_expl  \\\n",
       "explanation config                                              \n",
       "MUS                              403    0                 403   \n",
       "OUS Iter.+Lit. Incr. HS          403  403                 403   \n",
       "\n",
       "                         time_tavg_greedy_explain  \n",
       "explanation config                                 \n",
       "MUS                                           403  \n",
       "OUS Iter.+Lit. Incr. HS                         0  \n",
       "\n",
       "[2 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average speed-up from MUS -> OCUS best configuration: 56%\n"
     ]
    }
   ],
   "source": [
    "t_mus, t_ocus, t_diff = [], [], []\n",
    "\n",
    "df_mus_ocus = df_all_grows[\n",
    "    (df_all_grows[\"explanation config\"].isin([\"OUS Iter.+Lit. Incr. HS\", \"MUS\"])) & \n",
    "    (df_all_grows[\"params_grow_config\"].isin([\"SUBSETMAX SAT MCSes + Actual + Unif.\", \"MUS\"]))\n",
    "]\n",
    "display(df_mus_ocus.groupby(by=[\"explanation config\"]).count())\n",
    "\n",
    "for instance in set(df_mus_ocus[\"params_instance\"]):\n",
    "    t_mus_instance = float(df_mus_ocus[\n",
    "        (df_mus_ocus[\"params_instance\"] == instance) &\n",
    "        (df_mus_ocus[\"explanation config\"] == \"MUS\")\n",
    "    ][\"tot_time_explain\"])\n",
    "    \n",
    "    t_ocus_instance = float(df_mus_ocus[\n",
    "        (df_mus_ocus[\"params_instance\"] == instance) &\n",
    "        (df_mus_ocus[\"explanation config\"] == \"OUS Iter.+Lit. Incr. HS\")\n",
    "    ][\"tot_time_explain\"])\n",
    "    \n",
    "    t_mus.append(t_mus_instance)\n",
    "    t_ocus.append(t_ocus_instance)\n",
    "    t_diff_instance = (t_mus_instance - t_ocus_instance)/t_mus_instance\n",
    "    t_diff.append(t_diff_instance * 100)\n",
    "    #print(t_mus_instance, t_ocus_instance, t_diff_instance * 100)\n",
    "        \n",
    "print(f\"Average speed-up from MUS -> OCUS best configuration: {round(np.mean(t_diff))}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
