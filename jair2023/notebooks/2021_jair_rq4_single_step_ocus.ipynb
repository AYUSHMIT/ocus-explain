{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6c7d4b",
   "metadata": {},
   "source": [
    "Research QUestions:\n",
    "-------------------------\n",
    "\n",
    "(RQ1)  Cost comparison with more extensive benchmark dataset \n",
    "\n",
    "(RQ2)  Which domain specific grow helps improve the overal runtime?\n",
    "\n",
    "(RQ3)  How does extraction multiple correction subsets affect runtime\n",
    "\n",
    "    (a) as an initial bootstrapping method;\n",
    "    (b) as a replacement for grow and its complement.\n",
    "\n",
    "(RQ4)  What is the efficiency of a single step O(C)US and is single step sufficiently efficient for an interactive context?\n",
    "    \n",
    "    -> What is an “interactive context”?\n",
    "    -> Is the most difficult explanation faster in one over the other?\n",
    "    -> Did we have to explain the previous steps as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6838e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyexplain.benchmark.file_utils import *\n",
    "from pyexplain.benchmark.plot import *\n",
    "import IPython\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['font.weight']= 'bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8348f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_all_explanation_times(config_expl_times: dict, order, path=None):\n",
    "    #print(config_expl_times.keys())\n",
    "    max_t = 0\n",
    "    for label, v in config_expl_times.items():\n",
    "        max_t = max([max_t, max(v)])\n",
    "\n",
    "    bins=[0,0.1, 0.2, 0.3, 0.4, 0.5, 1,2,3,4, 5,10,20,30, 40, 50] + list(range(100, int(max_t//100 + 2)*100,100)) \n",
    "    v = []\n",
    "\n",
    "    #fig, axs = plt.subplots(figsize=(15, 8))\n",
    "    plt.figure(figsize =(15, 8))\n",
    "    colors = ['r','g','b', 'c','m','y']\n",
    "    \n",
    "    #for o, c in zip(order, colors):\n",
    "    plt.hist([config_expl_times[o] for o in order], bins=bins, label=order, stacked=True)\n",
    " \n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.legend()\n",
    "    if path:\n",
    "        plt.savefig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cc5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_individual_configs_explanation_times(config_expl_times: dict, order, path=None):\n",
    "    #print(config_expl_times.keys())\n",
    "    max_t = 0\n",
    "    for label, v in config_expl_times.items():\n",
    "        max_t = max([max_t, max(v)])\n",
    "\n",
    "    bins=[0,0.1, 0.2, 0.3, 0.4, 0.5, 1,2,3,4, 5,10,20,30, 40, 50] + list(range(100, int(max_t//100 + 2)*100,100)) \n",
    "    v = []\n",
    "\n",
    "    #fig, axs = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    colors = ['r','g','b', 'c','m','y']\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=len(order)//2,ncols=2, figsize=(20, 20))\n",
    "    for id, o in enumerate(order):\n",
    "        row, col = id//2, id%2\n",
    "        \n",
    "        axs[row, col].hist(config_expl_times[o], bins=bins, label=o, stacked=True)\n",
    "        axs[row, col].set_yscale('log')\n",
    "        axs[row, col].set_xscale('log')\n",
    "        axs[row, col].legend(fontsize=16)\n",
    "        axs[row, col].tick_params(axis = 'both', labelsize = 18)\n",
    "        \n",
    " \n",
    "    if path:\n",
    "        plt.savefig(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c62c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC\n",
    "environment = 'MAC'\n",
    "BASE_MAC_LINUX = {\n",
    "    'MAC': '/Users/emiliogamba/Documents/01_VUB/01_Research/01_Shared_Projects',\n",
    "    'LINUX': '/home/emilio/research/'\n",
    "}\n",
    "\n",
    "PATH_FIGURES_POST_PAPER = Path(BASE_MAC_LINUX[environment] + \"01_holygrail/latex/journal/jair21/figures/\")\n",
    "EXPERIMENT_RESULTS = Path(BASE_MAC_LINUX[environment] + \"06_HPC_Experiments/experiments/data/output/\")\n",
    "BASE_OUTPUT_PATH = BASE_MAC_LINUX[environment] + \"/06_HPC_Experiments/experiments/data/output/\"\n",
    "REMOTE_EXPERIMENT_RESULTS = \"/data/brussel/101/vsc10143/hpc_experiments2/experiments/data/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_configs_corr_output_folders = [\n",
    "    #\"RQ2_LOGIC_SUDOKU_PUZZLES/2022021411/\",\n",
    "    #\"RQ2_DEMYSTIFY_PUZZLES/2022021714/\",\n",
    "    \"RQ3b_DEMYSTIFY_PUZZLES/2022022217/\",\n",
    "    \"RQ3b_LOGIC_SUDOKU_PUZZLES/2022022217/\",\n",
    "]\n",
    "\n",
    "path_all_corr_output_dirs = [BASE_OUTPUT_PATH + o for o in all_configs_corr_output_folders]\n",
    "\n",
    "df_all_corr = folder_to_pandas_df_pickle(path_all_corr_output_dirs)\n",
    "\n",
    "## These instances are ignored because their first step derives a lot 100+ literals at once, which doesn't\n",
    "## represent 'good' explanations data instances\n",
    "ignored_instances = [ \"origin_origin.param_0_origin.param.json\",\n",
    "\"garam_garam_9_garam-vdiff-201120.param.json\",\n",
    "\"garam_garam_7_garam-easy-201120.param.json\",\n",
    "\"garam_garam_5_garam-exp-201120.param.json\",\n",
    "\"tents_tents_2_tents-1.param.json\",\n",
    "\"tents_tents_1_tectonic-9.param.json\",\n",
    "\"garam_garam_1_garam-adv-201120.param.json\",\n",
    "\"garam_garam_4_garam-fiend-201120.param.json\",\n",
    "\"tents_tents_3_tectonic-1-2-3-4-5-6-7.param.json\",\n",
    "\"garam_garam_10_garam-diff-201120.param.json\",\n",
    "\"pasta_pasta.param_0_pasta.param.json\",\n",
    "\"garam_garam_8_garam-medium-201120.param.json\",\n",
    "\"garam_garam_11_garam-tut.param.json\",\n",
    "\"kakuro_kakuro_3_1-row-col-restrictions.param.json\",\n",
    "\"kakuro_kakuro_0_conceptispuzzles.param.json\",\n",
    "\"garam_garam_2_garam-master-201120.param.json\",\n",
    "\"kakuro_kakuro_1_2-definitions-intersection.param.json\",\n",
    "\"garam_garam_3_garam-beg-201120.param.json\"]\n",
    "ignored_instances += [\"frietkot\", \"simple\"]\n",
    "ignored_instances += list(set(i for i in df_msg_enh[\"params_instance\"] if 'sudoku-4x4' in i))\n",
    "df_all_corr = df_all_corr[~df_all_corr[\"params_instance\"].isin(ignored_instances)].reset_index()\n",
    "\n",
    "df_all_corr = corr_enhance_df(df_all_corr)\n",
    "df_all_corr[\"tot_lits_derived\"] = df_all_corr.apply(lambda row: sum(row[\"lits_derived\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf78f5",
   "metadata": {},
   "source": [
    "## RQ4: What is the efficiency of a single step O(C)US and is single step sufficiently efficient for an interactive context?\n",
    "\n",
    "### (a) From an incremental (random explanation?) solving point of view ?\n",
    "### (b) From an instantaneous(time-to-first) explanation point of view ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e85fc7",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "There is only 1 best grow configuration for every explanation computer that is the best without bootstrapping , in this case:\n",
    "\n",
    "- Greedy CorrSubsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfb03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
